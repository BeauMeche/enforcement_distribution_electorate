---
title: "Replication: 'The Distributive Politics of Enforcement'"
author: "Beau Meche"
date: "2/21/2020"
output: 
  pdf_document:
    extra_dependencies: ["rotating"]
bibliography: "bibliography1.bib"
#biblio-style: "chicagolike"
link_citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# toolbox

# gt from github: 'remotes::install_github("rstudio/gt")'


library(tidyverse)
library(foreign)
library(stargazer)
library(tinytex)
library(gt)
library(bibtex)
library(rstanarm)
library(ggthemes)

```

#### Credit:
The Distributive Politics of Enforcement


Author: Alisha C. Holland


#### Introduction and Overview: 

This paper looks at police behavior in varying contexts around Latin America to explore what gets prosecuted and what is allowed to go unnoticed. The areas of interest are the relationships between constituency of the powers that be (at a given time) and how much those individuals in the constituent groups care to have property rights enforced. Involving a great deal of original research, the author does an intriguing job of addressing this question in a rather Bayesian way, so I thought this would be a good project on a topic that I briefly studied previously and can now apply new skills to. 

The author argues that in many cases, not enforcing these laws is as intentional as enforcing them and makes the early assertion of one of her findings where she found a five times higher enforcement rate in places where constituents were primarily non-poor (a binary distinction make in the data analysis portion of the research). Holland uses many standardized poisson regression models, which makes sense in the setting where response variables are the topic of interest. The catch in that model is the concern for invalidation by reverse causality. To counter this point, a supply vs. demand framework is raised as one might find in your favorite introductory economics course with the y-axis showing enforcement frequency and the x-axis showing offenses. The key to this argument is in assuming that the intentional non-enforcement cases would translate to an outward shift in the ‘supply curve’ of enforcement. This framework gives a decent basis to analyze electoral and otherwise political behavior and regional differences. The results of the data and the proposed model seem to support this framework and initial intuition, even if it is specific to the case observed. I would have concerns about the external validity of Holland’s model, but nonetheless I agree that the model results in support for the framework claiming that there is an inverse relationship between police enforcement of vending licensing and quantity of poor individuals voting in a district. 


#### <u>A Quote from the Abstract:</u>

"Why do some politicians tolerate the violation of the law? In contexts where the poor are the primary violators of property laws, I argue that the answer lies in the electoral costs of enforcement: Enforcement can decrease support from poor voters even while it generates support among nonpoor voters. Using an original data set on unlicensed street vending and enforcement operations at the subcity district level in three Latin American capital cities, I show that the combination of voter demographics and electoral rules explains enforcement. Supported by qualitative interviews, these findings suggest how the intentional nonenforcement of law, or forbearance, can be an electoral strategy. Dominant theories based on state capacity poorly explain the results."^[[“All analysis and output code for this replication project as well as the original paper are available here. ](https://github.com/BeauMeche/enforcement_distribution_electorate)]

-Alisha C. Holland
[@Holland14]

```{r load_and_triage_data}

# this was the link code before I did the bibliography: 
# <a href="https://github.com/BeauMeche/enforcement_distribution_electorate">link</a>

# this project was done in STATA, so transcribing the code will likely be rough
# as my knowledge of STATA is negligible


# may as well take everything out of the zip file

unzip("Holland_dataverse_repl_01.zip")

enforcement <- read.dta("Enforcement.dta")

enforce1 <- read_tsv("Enforcement.tab",
                     col_types = cols(
  .default = col_double(),
  city = col_character(),
  district = col_character()))


```


```{r data_exploration, echo=FALSE}

# 
# \newpage
# #### Initial Data Exploration


# 
# # variable "lower" is the share of lower-class residents in a given district
# 
# glimpse(enforce1)
# 
# enforcement %>% 
#   filter(city == "lima") %>%
#   ggplot(aes(x = corruption, y = operations)) +
#   geom_point(aes(color = poor)) +
#   labs(
#     title = "Corruption Coefficients and Police Activity",
#     x = "Number of Operations",
#     y = "Corruption Scale",
#     color = "% Poor
# Population"
#   ) +
#   scale_x_continuous(breaks = (seq(0,20, by= 2)))

```


\newpage

#### Proposed Extension and Addition to Human knowledge: 

Extending this academic work presents a particular challenge. The core of this research hinges on original data collected by the author through interviews and collection of data on site in Colombia, Chile, and Peru – places I have never been to nor have the means to go to now. In addition to this, there is at this point data missing from my possession that is temporal in nature. My ideal extension of this work relies on this temporal data.

As this paper was published in 2015, I would like to do an analysis of those same cities with data from the last five years. After making sure that the political and electoral systems are acceptably similar to the conditions which were posited in Holland’s work, it would be great to be able to test her methods as predictive models and observe their accuracy. This opens up a discussion regardless of the congruence, as high similarity supports her arguments and her modeling work and significant differences pose any number of questions about what has changed in the political sphere in the differential city. 

That said, and pending the not-insignificant chance that this data continues to be unavailable, I would like to further explore the concerns of reverse causality in this paper, either through instrumental variable regression or through the causal methods that we will cover in the near future in 1006. I was fascinated by the work and the logic in Holland’s paper, but there were several points of concern that I think warrant more testing and exploration to see whether these assumptions hold or whether they are conjecture that would lead to significant differences between the model’s predictions as mentioned above and reality now or in the future. In addition to this, and in the Bayesian spirit of data analysis, I think it would be interesting to look at the current data where decentralized is a binary variable and use this to look at whether this would be an informative practice in supporting Holland’s original work. 

As a third alternative, I am relatively familiar with OECD and health-related data sourcing. Holland showed in some ways how demographic variables were not necessarily informative to the topic of the study, but health and wellness data could be informative; especially in a setting where budget and poverty are core drivers and points of information. I do have the intuition at this point that I would still be relying on access to the temporal dataset used in the paper that is not included in the dataverse. 

Updated: My extension to this will focus on the role of missing data imputation and the underlying logic. 


\newpage

#### Literature Review

The author of this paper has become relatively well known for her research and her findings in the realm of forbearance and electoral impacts relative to low income populations in Latin America. In the literature published after this particular paper in 2014, a majority of it has also been authored by Holland and so far as I can tell there are few contradictions to be seen. The setting of the cases observed in this research is one where vendors of various goods are 'guilty' of using public space to peddle their private enterprises. This gives the police forces the ability to, within the letter of the law, arrest or otherwise enforce the statute that they are unlicensed to the space in question and that they should vacate. The reality tangent to this is that these vendors are also voters, and they are unlikely to forget the political head of the forces inhibiting their livelihood. Holland cites Colombia's National Data Archive with respect to the aspect that these vendors often do tend to rely on thier 'unlicensed incomes' as they are usually quite low-ranking in the income distribution.

Without digressing into Holland's research or the other supporting research again, it seems intuitive that where there is a majority of voters comprised of these individuals in the lower income distribution range who may rely, or know someone who relies, on secondary income to sustain themselves you would find that the local government would be less harsh on these cases of unregistered free markets. In fact, since this paper was published other authors have found cases where the government actually incentivizes the collaboration or unionization of these unregistered individuals as a sort of subset of the economy [@Hummel17]. 

Overall this vein of inquiry has fascinating ramifications in electoral predictions and voter behavior, especially in cases where statistical analyses show decreased sensitivities to potentially exogenous enforcement factors like department budgets and other angles. Carefully constructed models slowly begin to point their fingers toward constituency as a large driver of enforcement behaviors; and while I would prefer to see a few more rigors in the process, I tend to be convinced by the findings available thus far. 


```{r mstone_4_gtTable, echo=FALSE}

# no longer need the gt table for this project
# this page will have the project extension proposal on it

# gt1 <- enforcement %>% 
#   filter(city == "santiago") %>% 
#   select(arrests, city, district, population) %>% 
#   # mutate(marrest = mean(arrests),
#   #        mcorrupt = mean(corruption),
#   #        mtax = mean(tax)) %>% 
#   mutate(arrpercap = round(arrests/population, 3)) %>% 
#   group_by(district) %>% 
#   drop_na() %>% 
#   summarise(avg_arrestPC = mean(arrpercap))
# 
# gt1 %>%
#   # mutate(avg_arrests = round(`mean(arrests)`, 2)) %>%
#   # select(!`mean(arrests)`) %>%
#   arrange(desc(avg_arrestPC)) %>%
#   gt() %>%
#   fmt_percent(columns = vars(avg_arrestPC)) %>%
#   cols_label(avg_arrestPC = "Arrest Rate",
#              district = "District") %>%
#   tab_header(
#     title = "Average Per Capita Arrest Rate per District",
#     subtitle = "Districts from the city of Santiago"
#     )


```



```{r regressions1, echo=FALSE}

# this text was the description of the latter contained code

# \newpage
# #### Regression Table Attempt
# Stata would be nicer most likely, but here goes...
# The data used can be found in my github repo [@BMeche_proj_repo].
# 
# All regressions are prediction models of the number of police operations, in this case all operations in lima. Particularly interesting is the regression (4), where the glm regression predicts a decrease of $\approx 28$ operations on average when the district is poor vs. when it is not... things seem to change when the core constituency changes. 

# attempting to use the stargazer package... we'll see how this goes
lima <- enforcement %>% 
  filter(city == "lima")


m1 <- lm(data = lima, operations ~ vendors)

m2 <- lm(data = lima, operations ~ vendors + lower)

m3 <- lm(data = lima, operations ~ vendors + lower + budget)

m4 <- glm(data = lima, operations ~ poordistrict)

# couldn't get the top lables to cooperate, but the meat of the exercise is here

# check out the binary regression (4)... poor constituents get less harassments... wild

```


```{r}

# stargazer(m1, m2, m3, m4, type = "text")

```


```{r figure3_TL, echo=FALSE}

top_left <- enforce1 %>% 
  mutate(poordistrict = as.integer(poordistrict)) %>% 
  filter(city == "bogota") %>% 
  select(poordistrict, operations, vendors)

fit_a <- stan_glm(data = top_left, operations ~ vendors, refresh = 0)

# this is the plot for Bogota

TL <- top_left %>% 
  ggplot(aes(y = operations, x = vendors)) + 
  geom_point(aes(shape = factor(poordistrict))) + 
  scale_y_continuous(limits = c(0, 30), 
                     breaks = c(0, 5, 10, 15, 20, 25, 30)) +
  scale_x_continuous(limits = c(0, 12),
                     breaks = seq(0, 12, 2)) +
  geom_abline(slope = coef(fit_a)[2], 
              intercept = coef(fit_a)[1]) +
  labs(
    title = "",
    x = "Unlicensed Vendors (thousands), Bogota",
    y = "Police Operations",
    shape = "non-poor, poor")  + 
  theme(legend.position = "bottom")


# _______________________
# notes from meeting with Alice

#pch

#resize box / scale box

#piazza post about rescaling tables

```

```{r fake_data_reprex}

# fake data replication to resolve a ggplot query: ignore this code chunk


# library(tidyverse)
# 
# data(mtcars)
# 
# mtcars %>%  
#   ggplot(aes(y = cyl, x = hp)) + 
#   geom_point(aes(shape = factor(am))) + 
#   labs(x = "horse power rating",
#        y = "cylinders")
# 
# 
# 
#   
# library(tidyverse)
# 
# data(mtcars)
# 
# reprex(
# 
# mtcars %>%  
#   ggplot(aes(y = cyl, x = hp)) + 
#   geom_point(aes(shape = factor(am))) + 
#   labs(x = "horse power rating",
#        y = "cylinders")
# )


```



```{r fig3_TR, warning=F}

# missing value warning, unsure why, blocked for milestone 5

# this is the plot for Lima

top_right <- enforce1 %>% 
  mutate(poordistrict = as.integer(poordistrict)) %>% 
  filter(city == "lima") %>% 
  select(poordistrict, operations, vendors)

fit_b <- stan_glm(data = top_right, operations ~ vendors, refresh = 0)

TR <- top_right %>% 
  ggplot(aes(y = operations, x = vendors)) + 
  geom_point(aes(shape = factor(poordistrict))) + 
  scale_y_continuous(limits = c(0, 80), 
                     breaks = seq(0,80, 20)) +
  scale_x_continuous(limits = c(0, 12),
                     breaks = seq(0, 12, 2)) +
  geom_abline(slope = coef(fit_b)[2], 
              intercept = coef(fit_b)[1]) +
  labs(
    title = "",
    x = "Unlicensed Vendors (thousands), Lima",
    y = "Police Operations",
    shape = "non-poor, poor")  + 
  theme(legend.position="bottom")

```

```{r fig3_BL, echo=F}

# this is the plot for Santiago

bot_left <- enforce1 %>% 
  mutate(poordistrict = as.integer(poordistrict)) %>% 
  filter(city == "santiago") %>% 
  select(poordistrict, operations, vendors)

fit_c <- stan_glm(data = bot_left, operations ~ vendors, refresh = 0)

BL <- bot_left %>% 
  ggplot(aes(y = operations, x = vendors)) + 
  geom_point(aes(shape = factor(poordistrict))) + 
  scale_y_continuous(limits = c(0, 20), 
                     breaks = seq(0,80, 20)) +
  scale_x_continuous(limits = c(0, 12),
                     breaks = seq(0, 12, 2)) +
  geom_abline(slope = coef(fit_c)[2], 
              intercept = coef(fit_c)[1]) +
  labs(
    title = "",
    x = "Unlicensed Vendors (thousands), Santiago",
    y = "Police Operations",
    shape = "non-poor, poor")  + 
  theme(legend.position="bottom")

```

```{r fig3_BR, warning=F}

# this is the plot for Santiago (crime reports)

bot_right <- enforce1 %>% 
  mutate(poordistrict = as.integer(poordistrict)) %>% 
  filter(city == "santiago") %>% 
  select(poordistrict, arrests, reports)

fit_d <- stan_glm(data = bot_right, arrests ~ reports, refresh = 0)

BR <- bot_right %>% 
  ggplot(aes(y = arrests, x = reports)) + 
  geom_point(aes(shape = factor(poordistrict))) + 
  scale_y_continuous(limits = c(0, 20), 
                     breaks = seq(0, 20, 5)) +
  scale_x_continuous(limits = c(0, 60),
                     breaks = seq(0, 60, 10)) +
  geom_abline(slope = coef(fit_d)[2], 
              intercept = coef(fit_d)[1]) +
  labs(
    title = "",
    x = "Crime Reports (thousands), Santiago",
    y = "Police Arrests (thousands)",
    shape = "non-poor, poor") + 
  theme(legend.position="bottom")

```

```{r, bogota_regression, message=F, warning = F}
# table 2 partial replication w/ standardized coefficients
# mimicing the methods in the stata code file

library(robustHD)

tab2 <- enforce1 %>% 
  filter(city == "bogota") %>% 
  mutate(slower = standardize(x = lower, centerFun = mean, 
                              scaleFun = sd),
         svendors = standardize(x = vendors, centerFun = mean,
                                scaleFun = sd),
         sbudget = standardize(x = budget, 
                               centerFun = mean,
                               scaleFun = sd),
         spop = standardize(x = population,
                                   centerFun = mean,
                                   scaleFun = sd))

fit_t2 <- glm(operations ~ slower + svendors + sbudget + spop,
              data = tab2, family = poisson(link = "log"))

# stargazer(fit_t2, type = "text")

# poisson[] for reg model? 

# my.poisson.mod <- glm(fatalities ~ attack, family = "poisson", data = mydata)


```






```{r, message=F, warning=F, results='asis'}
# 
# \newpage
# #### This is my attempted replication of one of Holland's regression tables. 
# 
# The regression type is a log-likelihood regression. This regression was solely for Bogotá.

# stargazer(fit_t2)

# ![This is the Bogota section of Holland's table 2 for reference: ]("table2_bogota_portion_replication.png")

```




\newpage
#### "Beautiful" Graphic

```{r}

top_left %>% 
  ggplot(aes(y = operations, x = vendors)) + 
  geom_point(aes(shape = factor(poordistrict))) + 
  scale_y_continuous(limits = c(0, 30), 
                     breaks = c(0, 5, 10, 15, 20, 25, 30)) +
  scale_x_continuous(limits = c(0, 12),
                     breaks = seq(0, 12, 2)) +
  geom_abline(slope = coef(fit_a)[2], 
              intercept = coef(fit_a)[1],
              color = "blue") +
  labs(title = "Enforcing Vendors' Licenses: Bogotá, Columbia",
        subtitle = "Data showing the association between quantity of unlicensed street 
vendors and number of police operations in the area in question. A linear 
regression line is included to enphasize the slope of the reationship",
        caption = "Data from original research done by Alisha C. Holland. 
Find the original paper and reference to the associated 
dataverse at: https://doi.org/10.1111/ajps.12125",
        x = "Unlicensed Vendors (thousands), Bogotá",
        y = "Police Operations",
        shape = "Poor District Binary")  + 
  theme_hc() +
  theme(legend.position="bottom")

```


\newpage

#### Appendix: 

I was unable to recreate one graphic on account of not having access to political and temporal data that would allow me to create the graphic showing class gradient, budget, operations, and politicians in power for certain time frames. Otherwise, I have replicated or attempted to replicate all of the major analyses in the paper with the data I have access to. Items made by the author with data unaccessible and graphs pertaining to only theory were not replicated on basis of not being relevant to course scope. 



```{r fig3_grid, message=F, warning=F}

library(cowplot)

plot_grid(TL, TR); plot_grid(BL, BR)

```
![This is Holland's Figure 3 for reference: ]("holland_figure3_appendix_pic.png")

```{r figure_4_holland_rep}

# this is all code in attempt to replicate the methods, which I understand, 
# used in the replication done in stata. 

# within figure 2, poisson regression predictions divided by the average predictions # is the y-axis value. I have managed to get some kind of prediction output, but 
# am currently unable to correlate that information back to the data in a usable/ 
# meaningful way. 

# this was a calculation for the mean operation count by city
# to check my hunch from the stata file... which was correct : )

op_mean <- enforce1 %>% 
  group_by(city) %>% 
  summarize(mean(operations)) %>% 
  arrange()
  

 # dummy code that was functional but irrelevant
# 
# mutate(exp_div_avg_ops = case_when(
#     city == "bogota" ~ operations/8.8947,
#     city == "lima" ~ operations/8.8947,
#     city == "santiago" ~ operations/8.8947)) %>%
#   ungroup() %>%
#   select(operations, exp_div_avg_ops, vendors, lower, city)

# created an average operations row

enforce1 <- enforce1 %>% 
  mutate(m.ops = mean(operations))

# mimicing the regression from the stata file (that is unlike the regression used
# in the regression table)

fit_f2 <- glm(operations ~ lower + vendors + budget + population,
              data = enforce1, family = poisson(link = "log"))

# the source code says to re-run the prediction code under various conditions, 
# this is my working attempt at this with "new" data as we have done in class
# and also how I understand predicted / expected value to work

new.lower1 <- data.frame(lower = seq(0,100,10),
                         vendors = mean(enforce1$vendors),
                         budget = mean(enforce1$budget),
                         population = mean(enforce1$population))

new.lower2 <- data.frame(lower = mean(enforce1$lower),
                         vendors = seq(0,15,1),
                         budget = mean(enforce1$budget),
                         population = mean(enforce1$population))

pred1 <- predict(fit_f2, newdata = new.lower1)

pred2 <- predict(fit_f2, newdata = new.lower2)

# q1 <- cbind(pred1, pred2)

# plot(q1)

    # error: number of rows of result is not a multiple of vector length (arg 1)

# output code that is ugly and thus kept out of the knit product

# plot(pred1)
# plot(pred2)
# print(fit_f2)

# plot(y = enforce1$operations, x = pred1)


```

```{r fig_2_placeholder, warning=F}

# removing message about removed rows

bog_mean <- pull(op_mean[1,2])

pt1 <- enforce1 %>%
  filter(lower >= 0 & lower <= 70) %>% 
  ggplot(aes(y = operations/bog_mean,
             x = lower)) +
  geom_smooth(aes(group = city,
                color = city),
                method = "glm",
                se = T) +
  scale_y_continuous(limits = c(0,5),
                     breaks = seq(0,5,1)) +
  scale_x_continuous(breaks = seq(0,70,20)) +
  labs(
    title = "The following graphs are my closest attempt at figure 2",
    y = "operations / average ops. in Bogota",
    x = "Percent lower class"
  )


pt2 <- enforce1 %>%
  filter(vendors >= 0 & vendors <= 12) %>% 
  ggplot(aes(y = operations/bog_mean,
             x = vendors)) +
  geom_smooth(aes(group = city,
                color = city),
                method = "glm",
                se = T) +
  scale_y_continuous(limits = c(0,5),
                     breaks = seq(0,5,1)) +
  scale_x_continuous(breaks = seq(0,12,3)) +
  labs(
    y = "operations / average ops. in Bogota",
    x = "Unlicensed Vendors (thousands)"
  )

# pt1; pt2


```

```{r, bogota_regression2, message=F, warning = F}
# table 2 partial replication w/ standardized coefficients
# mimicing the methods in the stata code file

library(robustHD)

tab2 <- enforce1 %>% 
  filter(city == "bogota") %>% 
  mutate(slower = standardize(x = lower, centerFun = mean, 
                              scaleFun = sd),
         svendors = standardize(x = vendors, centerFun = mean,
                                scaleFun = sd),
         sbudget = standardize(x = budget, 
                               centerFun = mean,
                               scaleFun = sd),
         spop = standardize(x = population,
                                   centerFun = mean,
                                   scaleFun = sd))

fit_t2 <- glm(operations ~ slower + svendors + sbudget + spop,
              data = tab2, family = poisson(link = "log"))

# stargazer(fit_t2, type = "text")


```

```{r lima_regressions, message=F, warning=F}

# tab2_lima

tab2l <- enforce1 %>% 
  filter(city == "lima") %>% 
  mutate(slower = standardize(x = lower, centerFun = mean, 
                            scaleFun = sd),
       svendors = standardize(x = vendors, centerFun = mean,
                              scaleFun = sd),
       sbudget = standardize(x = budget, 
                             centerFun = mean,
                             scaleFun = sd),
       spop = standardize(x = population,
                                 centerFun = mean,
                                 scaleFun = sd),
       smargin = standardize(x = margin, centerFun = mean,
                             scaleFun = sd),
       int_ML = lower * margin,
       s.int_ML = standardize(x = int_ML, centerFun = mean,
                              scaleFun = sd))

fit_t2_lim1 <- glm(operations ~ slower + svendors + sbudget + spop,
              data = tab2l, family = poisson(link = "log"))

fit_t2_lim2 <- glm(operations ~ slower + svendors + sbudget + spop + smargin,
              data = tab2l, family = poisson(link = "log"))

fit_t2_lim3 <- glm(operations ~ slower + svendors + sbudget + spop + smargin +
                     s.int_ML,
              data = tab2l, family = poisson(link = "log"))

# stargazer(fit_t2_lim1, fit_t2_lim2, fit_t2_lim3, type = "text")
  

```


```{r santiago_regressions, warning=F, message=F, results='asis'}

# tab2_santiago

tab2s <- enforce1 %>% 
  filter(city == "santiago") %>% 
  mutate(slower = standardize(x = lower, centerFun = mean, 
                            scaleFun = sd),
       svendors = standardize(x = vendors, centerFun = mean,
                              scaleFun = sd),
       sbudget = standardize(x = budget, 
                             centerFun = mean,
                             scaleFun = sd),
       spop = standardize(x = population,
                                 centerFun = mean,
                                 scaleFun = sd),
       smargin = standardize(x = margin, centerFun = mean,
                             scaleFun = sd),
       int_ML = lower * margin,
       s.int_ML = standardize(x = int_ML, centerFun = mean,
                              scaleFun = sd))

fit_t2_s1 <- glm(operations ~ slower + svendors + sbudget + spop,
              data = tab2s, family = poisson(link = "log"))

fit_t2_s2 <- glm(operations ~ slower + svendors + sbudget + spop + smargin,
              data = tab2s, family = poisson(link = "log"))

fit_t2_s3 <- glm(operations ~ slower + svendors + sbudget + spop + smargin +
                     s.int_ML,
              data = tab2s, family = poisson(link = "log"))

fit_t2_s4 <- glm(operations ~ slower + svendors + sbudget + spop + right,
              data = tab2s, family = poisson(link = "log"))

fit_t2_s5 <- glm(operations ~ slower + svendors + sbudget + spop + right + arrests,
              data = tab2s, family = poisson(link = "log"))


stargazer(fit_t2,
          fit_t2_lim1, fit_t2_lim2, fit_t2_lim3,
          fit_t2_s1, fit_t2_s2, fit_t2_s3, fit_t2_s4, fit_t2_s5,
          title = "Santiago",
          covariate.labels=c("Lower", "Vendors", "Budget", "Population", "Margin",
                             "Margin*Lower", "Right", "Reports"),
          float.env = "sidewaystable", 
          no.space = TRUE,
          column.labels = c("Bogota", "Lima", "Santiago"),
          column.separate = c(1, 3, 5))

```







